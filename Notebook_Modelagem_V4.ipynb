{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">> # Modelo preditivo -  Aguas do Brasil\n",
    "- Modelagem preditiva para  Devedores e CPC com base em título e títulos pagos e informações do telefone\n",
    "- Este Jupyter contém as etapas de ETL e Modelagem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importando pacotes e bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import os , gc, time, urllib, pyodbc, warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from datetime import date, timedelta\n",
    "import sqlalchemy as sql\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ETL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Engine.connect of Engine(mssql+pyodbc:///?odbc_connect=DRIVER%3D%7BSQL+Server+Native+Client+11.0%7D%3BSERVER%3D10.10.220.100%3BDATABASE%3DdbActyon_GAB%3BUID%3Dralisson.local%3BPWD%3DA4TIL%26fRplPn%3BTrusted_Connection%3Dno)>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = urllib.parse.quote_plus(\"DRIVER={SQL Server Native Client 11.0};\"\n",
    "                                 \"SERVER=10.10.220.100;\"\n",
    "                                 \"DATABASE=dbActyon_GAB;\" # trocar o nome da operação\n",
    "                                 \"UID=ralisson.local;\"\n",
    "                                 \"PWD=A4TIL&fRplPn;\"\n",
    "                                 \"Trusted_Connection=no\")\n",
    "engine = sql.create_engine(\"mssql+pyodbc:///?odbc_connect={}\".format(params))\n",
    "engine.connect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Criando variavei de datas para coleta da query sql\n",
    "\n",
    "TODAY = date.today()\n",
    "YESTERDAY = date.today() - timedelta(days=200)\n",
    "data_inicio = f\"{YESTERDAY.year}-{YESTERDAY.month}-{YESTERDAY.day}\" #yesterday \n",
    "data_final = f\"{TODAY.year}-{TODAY.month}-{TODAY.day}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importando dados do banco de dados SQL\n",
    "\n",
    "query = '''\n",
    "\n",
    "    SELECT distinct\n",
    "        tbtitulo.TITULO_ID,\n",
    "        tbdevedor.CEP,\n",
    "        tbdevedor_fone.ORIGEM,\n",
    "        tbdevedor_fone.TIPO,\n",
    "        tbdevedor.QTDE_TITULOS,\n",
    "        tbdevedor.VALOR_DIVIDA_ATIVA,\n",
    "        tbtitulo_contrato_indicador.INDICADOR,\n",
    "        tbtitulo_pago.TIPO_BAIXA\n",
    "\n",
    "    FROM tbtitulo  (NOLOCK)\n",
    "        JOIN tbtitulo_pago  (NOLOCK) ON tbtitulo.TITULO_ID = tbtitulo_pago.TITULO_ID\n",
    "        JOIN tbdevedor  (NOLOCK) ON tbdevedor.DEVEDOR_ID = tbtitulo.DEVEDOR_ID\n",
    "        JOIN tbdevedor_fone  (NOLOCK) ON tbdevedor.DEVEDOR_ID = tbdevedor_fone.DEVEDOR_ID\n",
    "        JOIN tbtitulo_contrato_indicador  (NOLOCK) ON tbdevedor.DEVEDOR_ID = tbtitulo_contrato_indicador.DEVEDOR_ID\n",
    "\n",
    "    WHERE tbdevedor_fone.STATUS = 0\n",
    "    AND tbdevedor.DATA_IMPORTACAO between\n",
    "    \n",
    "\n",
    "'''\n",
    "#df = pd.read_sql(query, engine)\n",
    "df = pd.read_sql(query + f\"'{data_inicio}' AND '{data_final}'\", engine)\n",
    "print(\"tamanho da tabela: \", df.shape)\n",
    "\n",
    "engine.dispose()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates()\n",
    "#df.dropna(inplace = True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Engenharia de Atributos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Trabalhando com datas\n",
    "TODAY = date.today()\n",
    "TODAY = pd.to_datetime(TODAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#alterando tipo das featrures\n",
    "df['TIPO_BAIXA'] = df['TIPO_BAIXA'].astype('category')\n",
    "df['CEP'] = df['CEP'].astype('category')\n",
    "df['TITULO_ID'] = df['TITULO_ID'].astype(str)\n",
    "df['ORIGEM'] = df['ORIGEM'].astype('category')\n",
    "df['INDICADOR'] = df['INDICADOR'].astype('category')\n",
    "df['TIPO'] = df['TIPO'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.TIPO_BAIXA.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Variavel alvo Pagamento de títulos\n",
    "df['TARGET']  = df['TIPO_BAIXA'].replace(['1', '2' , '4','5', '3', '8','7',None, '0'], ['Nao_pagamento','Nao_pagamento', 'Nao_pagamento',\n",
    "                                                                    'Nao_pagamento','Nao_pagamento','Nao_pagamento','Nao_pagamento','Nao_pagamento','Pagamento'])\n",
    "df['TARGET']  = df['TARGET'].replace(['Nao_pagamento','Pagamento' ], [0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.TARGET.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(frac=0.1).boxplot('VALOR_DIVIDA_ATIVA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(frac=0.1).boxplot('QTDE_TITULOS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.query('VALOR_DIVIDA_ATIVA < 10000')\n",
    "df = df.query('QTDE_TITULOS < 200 ')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['TIPO_BAIXA'], inplace=True)\n",
    "df.drop_duplicates(inplace=True)\n",
    "df.dropna(inplace=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre Processamento dos dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Balanceamento de Variáveis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_count = df['TARGET'].value_counts()\n",
    "print('Class 0:', target_count[0])\n",
    "print('Class 1:', target_count[1])\n",
    "print('Proportion:', round(target_count[0] / target_count[1], 2), ': 1')\n",
    "target_count.plot(kind='bar', title='Count (TARGET)',color = ['#1F77B4', '#FF7F0E']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONTAR CLASSES\n",
    "count_class_0, count_class_1 = df['TARGET'].value_counts()\n",
    "# Divide by class\n",
    "df_class_0 = df[df['TARGET'] == 0]\n",
    "df_class_1 = df[df['TARGET'] == 1]\n",
    "df_class_0_under = df_class_0.sample(count_class_1)\n",
    "df = pd.concat([df_class_0_under, df_class_1], axis=0)\n",
    "print('Random under-sampling:')\n",
    "print(df['TARGET'].value_counts())\n",
    "df['TARGET'].value_counts().plot(kind='bar', title='Count (TARGET)',color = ['#1F77B4', '#FF7F0E']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df[[ 'QTDE_TITULOS', 'VALOR_DIVIDA_ATIVA', 'CEP' , 'INDICADOR']] \n",
    "features_cpc = df[[ 'QTDE_TITULOS', 'VALOR_DIVIDA_ATIVA' , 'CEP', 'ORIGEM', 'TIPO']] \n",
    "target = df[['TARGET']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Padronização ou Normalização das variáveis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "features['CEP']= le.fit_transform(features[\"CEP\"])\n",
    "features['INDICADOR']= le.fit_transform(features[\"INDICADOR\"])\n",
    "\n",
    "features_cpc['ORIGEM']= le.fit_transform(features_cpc[\"ORIGEM\"])\n",
    "features_cpc['TIPO']= le.fit_transform(features_cpc[\"TIPO\"])\n",
    "features_cpc['CEP']= le.fit_transform(features_cpc[\"CEP\"])\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "features['QTDE_TITULOS'] = scaler.fit_transform(features[['QTDE_TITULOS']])\n",
    "features['VALOR_DIVIDA_ATIVA'] = scaler.fit_transform(features[['VALOR_DIVIDA_ATIVA']])\n",
    "\n",
    "features_cpc['QTDE_TITULOS'] = scaler.fit_transform(features_cpc[['QTDE_TITULOS']])\n",
    "features_cpc['VALOR_DIVIDA_ATIVA'] = scaler.fit_transform(features_cpc[['VALOR_DIVIDA_ATIVA']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_class_0\n",
    "del df_class_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelagem preditiva"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelagem Preditiva com O algoritimo Devedor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avaliação do modelo usando o XGBoost\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "inicio = time.time()\n",
    "\n",
    "# Divide os dados em treino e teste\n",
    "X = features\n",
    "Y = target\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.30, random_state = 5)\n",
    "\n",
    "# Criando o modelo\n",
    "Model = XGBClassifier(colsample_bytree=0.2, gamma=0, gpu_id=-1, learning_rate=0.2,  max_depth=6, n_estimators=150, n_jobs=48,\n",
    "                         nthread=48, num_parallel_tree=1, random_state=0, subsample=0.2 ) \n",
    "\n",
    "# Treinando o modelo\n",
    "Model.fit(X_train, Y_train)\n",
    "\n",
    "# Previsão do modelo\n",
    "Predict = Model.predict(X_test)\n",
    "report = classification_report(Y_test, Predict)\n",
    "\n",
    "# Imprimindo o relatório\n",
    "print(report)\n",
    "\n",
    "fim = time.time()\n",
    "print(\"o tempo de execução foi de: \", fim - inicio, \"segundos,  ou \",(fim - inicio)/60, \"minutos\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análise de Features e Acurácia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleção dos melhores atributos como resultado para a modelagem CPC\n",
    "gc.collect()\n",
    "Model.feature_importances_\n",
    "feature_importances = pd.DataFrame(Model.feature_importances_,\n",
    "                                   index = X.columns,\n",
    "                                   columns=['importance']).sort_values('importance', ascending=False)\n",
    "feature_importances\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvando o modelo Propensao a pagar\n",
    "import pickle\n",
    "\n",
    "arquivo_cpf = '../models/modelo_v1_devedor.sav'\n",
    "pickle.dump(Model, open(arquivo_cpf, 'wb'))\n",
    "print(\"Modelo salvo!\")\n",
    "\n",
    "# Salvar as features do modelo\n",
    "with open('NameFeature_v1_devedor','wb') as arquivo_cpf:\n",
    "   pickle.dump(features.columns, arquivo_cpf)\n",
    "\n",
    "print('Nomes Salvo')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelagem Preditiva CPC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avaliação do modelo usando o XGBoost\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "inicio = time.time()\n",
    "\n",
    "# Divide os dados em treino e teste\n",
    "X = features_cpc\n",
    "Y = target\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.30, random_state = 5)\n",
    "\n",
    "# Criando o modelo\n",
    "Model_cpc = XGBClassifier(colsample_bytree=0.2, gamma=0, gpu_id=-1, learning_rate=0.2,  max_depth=6, n_estimators=150, n_jobs=48,\n",
    "                         nthread=48, num_parallel_tree=1, random_state=0, subsample=0.2 ) \n",
    "\n",
    "# Treinando o modelo\n",
    "Model_cpc.fit(X_train, Y_train)\n",
    "\n",
    "# Previsão do modelo\n",
    "Predict = Model_cpc.predict(X_test)\n",
    "report = classification_report(Y_test, Predict)\n",
    "\n",
    "# Imprimindo o relatório\n",
    "print(report)\n",
    "\n",
    "fim = time.time()\n",
    "print(\"o tempo de execução foi de: \", fim - inicio, \"segundos,  ou \",(fim - inicio)/60, \"minutos\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleção dos melhores atributos como resultado para a modelagem CPC\n",
    "gc.collect()\n",
    "Model_cpc.feature_importances_\n",
    "feature_importances = pd.DataFrame(Model_cpc.feature_importances_,\n",
    "                                   index = X.columns,\n",
    "                                   columns=['importance']).sort_values('importance', ascending=False)\n",
    "feature_importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvando o modelo CPC\n",
    "import pickle\n",
    "\n",
    "arquivo_cpc = '../models/modelo_v1_cpc.sav'\n",
    "pickle.dump(Model_cpc, open(arquivo_cpc, 'wb'))\n",
    "print(\"Modelo salvo!\")\n",
    "\n",
    "# Salvar as features do modelo\n",
    "with open('NameFeature_v1_cpc','wb') as arquivo_cpc:\n",
    "   pickle.dump(features_cpc.columns, arquivo_cpc)\n",
    "\n",
    "print('Nomes Salvo')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy do modelo"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3e7ffb16807c612527859a4be59be6cdfc3f0bdfc5c07886aa766faef6ede9b2"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
